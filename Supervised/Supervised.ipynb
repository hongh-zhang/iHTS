{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "a2cac224-165a-4eea-9c81-bce945d5684b",
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "\n",
    "import typing\n",
    "from typing import List, Iterable\n",
    "import pickle\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "import rdkit\n",
    "from rdkit.Chem import AllChem as AllChem\n",
    "from rdkit.SimDivFilters.rdSimDivPickers import MaxMinPicker\n",
    "\n",
    "import lightgbm as lgb\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.linear_model import SGDClassifier\n",
    "from sklearn.model_selection import cross_validate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "a30c25a7-1337-41f4-a036-2166dfe88f9e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(63662, 1121) (63662,)\n"
     ]
    }
   ],
   "source": [
    "with open(\"AID_628/data.pkl\",\"rb\") as file:\n",
    "    data = pickle.load(file)\n",
    "    \n",
    "smiles_ls = data.get(\"smiles_ls\")\n",
    "mol_ls = data.get(\"mol_ls\")\n",
    "fp_ls = data.get(\"fp_ls\")\n",
    "activity_ls = data.get(\"activity_ls\")\n",
    "ds_ls = data.get(\"ds_ls\")\n",
    "\n",
    "del data\n",
    "\n",
    "X = np.concatenate([np.array(ds_ls), np.array(fp_ls)], axis=1)\n",
    "y = np.array(activity_ls)\n",
    "print(X.shape, y.shape)\n",
    "\n",
    "SEED = 0\n",
    "P_INIT = 0.15\n",
    "P_ITER = 0.05\n",
    "N_ITER = 4\n",
    "P_EXPLOIT = 0.8\n",
    "N_TOTAL = len(fp_ls)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "b7649153-a379-4842-86c5-5093ea0a0e1a",
   "metadata": {},
   "outputs": [],
   "source": [
    "N_JOBS = 4\n",
    "\n",
    "# define model\n",
    "rf = RandomForestClassifier(n_estimators=1200, class_weight=\"balanced\",\n",
    "    max_features='log2',bootstrap=True,min_samples_split = 8,\n",
    "    min_samples_leaf = 3, n_jobs = N_JOBS,random_state=SEED)\n",
    "\n",
    "svm = SGDClassifier(loss='hinge', penalty='l2', alpha=0.0001, l1_ratio=0.15,\n",
    "    fit_intercept=True, max_iter=10000,tol=0.001, shuffle=True, verbose=0,\n",
    "    epsilon=0.1, n_jobs=N_JOBS, random_state=None, learning_rate='optimal',\n",
    "    eta0=0.0007, power_t=0.5, class_weight='balanced', warm_start=False,\n",
    "    average=5)\n",
    "\n",
    "lgbm = lgb.LGBMClassifier(boosting_type='dart', num_leaves=42, max_depth=-1,\n",
    "    learning_rate=0.25, n_estimators=1200, subsample_for_bin=200000,\n",
    "    objective='binary', is_unbalance=False, max_bin=200,\n",
    "    min_child_weight=0.001, min_child_samples=30, subsample=1.0,\n",
    "    subsample_freq=0, colsample_bytree=1.0, reg_alpha=0.0, reg_lambda=0.0,\n",
    "    random_state=None, n_jobs=N_JOBS, silent=True,\n",
    "    importance_type='split')\n",
    "\n",
    "\n",
    "model_ls = [rf, svm, lgbm]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "f816b72c-a667-4b8a-a8ba-6f9b23ed9b99",
   "metadata": {
    "scrolled": true,
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Warning] Unknown parameter: silent\n",
      "[LightGBM] [Warning] Unknown parameter: silent\n",
      "[LightGBM] [Info] Number of positive: 1744, number of negative: 49185\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.115025 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 16402\n",
      "[LightGBM] [Info] Number of data points in the train set: 50929, number of used features: 1119\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.034244 -> initscore=-3.339407\n",
      "[LightGBM] [Info] Start training from score -3.339407\n",
      "[LightGBM] [Warning] Unknown parameter: silent\n",
      "[LightGBM] [Warning] Unknown parameter: silent\n",
      "[LightGBM] [Warning] Unknown parameter: silent\n",
      "[LightGBM] [Warning] Unknown parameter: silent\n",
      "[LightGBM] [Info] Number of positive: 1744, number of negative: 49185\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.155851 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 16486\n",
      "[LightGBM] [Info] Number of data points in the train set: 50929, number of used features: 1119\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.034244 -> initscore=-3.339407\n",
      "[LightGBM] [Info] Start training from score -3.339407\n",
      "[LightGBM] [Warning] Unknown parameter: silent\n",
      "[LightGBM] [Warning] Unknown parameter: silent\n",
      "[LightGBM] [Warning] Unknown parameter: silent\n",
      "[LightGBM] [Warning] Unknown parameter: silent\n",
      "[LightGBM] [Info] Number of positive: 1744, number of negative: 49186\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.122882 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 16515\n",
      "[LightGBM] [Info] Number of data points in the train set: 50930, number of used features: 1119\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.034243 -> initscore=-3.339428\n",
      "[LightGBM] [Info] Start training from score -3.339428\n",
      "[LightGBM] [Warning] Unknown parameter: silent\n",
      "[LightGBM] [Warning] Unknown parameter: silent\n",
      "[LightGBM] [Warning] Unknown parameter: silent\n",
      "[LightGBM] [Warning] Unknown parameter: silent\n",
      "[LightGBM] [Info] Number of positive: 1744, number of negative: 49186\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.145235 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 16476\n",
      "[LightGBM] [Info] Number of data points in the train set: 50930, number of used features: 1119\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.034243 -> initscore=-3.339428\n",
      "[LightGBM] [Info] Start training from score -3.339428\n",
      "[LightGBM] [Warning] Unknown parameter: silent\n",
      "[LightGBM] [Warning] Unknown parameter: silent\n",
      "[LightGBM] [Warning] Unknown parameter: silent\n",
      "[LightGBM] [Warning] Unknown parameter: silent\n",
      "[LightGBM] [Info] Number of positive: 1744, number of negative: 49186\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.151921 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 16371\n",
      "[LightGBM] [Info] Number of data points in the train set: 50930, number of used features: 1118\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.034243 -> initscore=-3.339428\n",
      "[LightGBM] [Info] Start training from score -3.339428\n",
      "[LightGBM] [Warning] Unknown parameter: silent\n",
      "[LightGBM] [Warning] Unknown parameter: silent\n"
     ]
    }
   ],
   "source": [
    "scoring = ['accuracy', 'precision', 'recall', 'roc_auc',]\n",
    "scores = cross_validate(rf, X, y, scoring=scoring)\n",
    "scores_ls = [cross_validate(model, X, y, scoring=scoring) for model in model_ls]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "343cb5f3-b31e-4b58-92fb-7e64db20a5e2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[{'fit_time': array([94.21736455, 91.98897028, 89.56756973, 92.68861818, 92.38944411]),\n",
       "  'score_time': array([6.17101908, 8.45499635, 6.12318063, 5.78977561, 6.04073596]),\n",
       "  'test_accuracy': array([0.96654363, 0.96560119, 0.96591266, 0.966541  , 0.96567703]),\n",
       "  'test_precision': array([0.91666667, 0.44444444, 0.55555556, 0.72727273, 0.48571429]),\n",
       "  'test_recall': array([0.02522936, 0.01834862, 0.02293578, 0.03669725, 0.03899083]),\n",
       "  'test_roc_auc': array([0.68786207, 0.67512868, 0.67593362, 0.68861564, 0.77434893])},\n",
       " {'fit_time': array([1.30261183, 6.03028321, 1.50522566, 1.49150443, 8.75233364]),\n",
       "  'score_time': array([0.1477282 , 0.0899713 , 0.09896803, 0.09600353, 0.08252239]),\n",
       "  'test_accuracy': array([0.03424173, 0.03424173, 0.03424442, 0.03424442, 0.03424442]),\n",
       "  'test_precision': array([0.03424173, 0.03424173, 0.03424442, 0.03424442, 0.03424442]),\n",
       "  'test_recall': array([1., 1., 1., 1., 1.]),\n",
       "  'test_roc_auc': array([0.57235533, 0.55648838, 0.57013133, 0.55605164, 0.55263739])},\n",
       " {'fit_time': array([62.06702995, 71.97968698, 67.49083471, 69.867944  , 66.35618138]),\n",
       "  'score_time': array([0.76760602, 0.72699761, 0.72742939, 0.68557048, 0.69199991]),\n",
       "  'test_accuracy': array([0.96607241, 0.96591534, 0.96559849, 0.96630537, 0.96544141]),\n",
       "  'test_precision': array([0.625     , 0.53333333, 0.45454545, 0.60606061, 0.46666667]),\n",
       "  'test_recall': array([0.02293578, 0.03669725, 0.02293578, 0.04587156, 0.06422018]),\n",
       "  'test_roc_auc': array([0.64063306, 0.63098872, 0.63869189, 0.64889343, 0.70959919])}]"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "scores_ls\n",
    "\n",
    "# svm fitted everything to positive...\n",
    "\n",
    "# rf > lgbm in auc, lgbm > rf in recall"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "2907ca8d-5ca3-4796-8ec9-e86b927ec8fd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1, 2]\n",
      "[0, 3, 4, 5, 6, 7, 8, 9]\n",
      "[8, 1, 2]\n",
      "[0, 3, 4, 5, 6, 7, 9]\n",
      "[8, 1, 2]\n",
      "[0, 3, 4, 5, 6, 7, 9]\n"
     ]
    }
   ],
   "source": [
    "def random_pick(fp_ls: List[rdkit.DataStructs.cDataStructs.ExplicitBitVect], \n",
    "                n: int, \n",
    "                seed: int = 42) -> List[int]:\n",
    "    \"\"\"Random diverse compound picking based on Rdkit MaxMinPicker\"\"\"\n",
    "    picker = MaxMinPicker()\n",
    "    return list(picker.LazyBitVectorPick(fp_ls, len(fp_ls), n, seed=seed))\n",
    "\n",
    "\n",
    "class Indice():\n",
    "    def __init__(self, size: int) -> None:\n",
    "        self.unsampled = list(range(size))\n",
    "        self.sampled = []\n",
    "        \n",
    "    def add(self, idxs: Iterable[int]) -> None:\n",
    "        self.sampled = list(set(self.sampled + list(idxs)))\n",
    "        self.unsampled = list(set(self.unsampled) - set(self.sampled))\n",
    "\n",
    "# test\n",
    "idxs = Indice(10)\n",
    "\n",
    "idxs.add([1,2])\n",
    "print(idxs.sampled)\n",
    "print(idxs.unsampled)\n",
    "\n",
    "idxs.add([1,2,8])\n",
    "print(idxs.sampled)\n",
    "print(idxs.unsampled)\n",
    "\n",
    "idxs.add([1,2,8])\n",
    "print(idxs.sampled)\n",
    "print(idxs.unsampled)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "2422b8f8-2b8c-4e8d-8482-d6f6fe26fab6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.16559633027522935\n",
      "0.36009174311926606\n",
      "0.4651376146788991\n",
      "0.5344036697247706\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0.594954128440367"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "clf = RandomForestClassifier(n_estimators=1200, class_weight=\"balanced\",\n",
    "    max_features='log2',bootstrap=True,min_samples_split = 8,\n",
    "    min_samples_leaf = 3, n_jobs = 4,random_state=SEED)\n",
    "\n",
    "# select initial subset\n",
    "init_idx = random_pick(fp_ls, int(P_INIT*len(fp_ls)))\n",
    "idxs = Indice(len(fp_ls))\n",
    "idxs.add(init_idx)\n",
    "\n",
    "for _ in range(N_ITER):\n",
    "    \n",
    "    print(np.array(activity_ls)[idxs.sampled].sum() / np.array(activity_ls).sum())\n",
    "    \n",
    "    # train supversied model\n",
    "    # form dataset\n",
    "    X_sampled = X[idxs.sampled]\n",
    "    y_sampled = y[idxs.sampled]\n",
    "    X_unsampled = X[idxs.unsampled]\n",
    "\n",
    "    # fit & make prediction\n",
    "    clf.fit(X_sampled, y_sampled)\n",
    "    probs = clf.predict_proba(X_unsampled)[:,0]  # prob of being inactive\n",
    "\n",
    "    # select next batch\n",
    "    # add exploitation set\n",
    "    n_exploit = int(P_ITER * N_TOTAL * P_EXPLOIT)\n",
    "    idx_exploit = np.argsort(probs)[:n_exploit]  # sorted from low -> high\n",
    "    idxs.add(np.array(idxs.unsampled)[idx_exploit])\n",
    "\n",
    "    # add exploration set\n",
    "    n_explore = int(P_ITER * N_TOTAL * (1-P_EXPLOIT))\n",
    "    idx_explore = random_pick([fp_ls[i] for i in idxs.unsampled], n_explore)\n",
    "    idxs.add(np.array(idxs.unsampled)[idx_explore])\n",
    "\n",
    "np.array(activity_ls)[idxs.sampled].sum() / np.array(activity_ls).sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "82e0d7f7-6b1f-420d-9bac-6ec07a9d319a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1297,)"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ytrue_idxs = np.where(np.array(activity_ls))[0]\n",
    "ytrue = np.array(smiles_ls)[ytrue_idxs]\n",
    "\n",
    "yhat_idxs = np.where(np.array(activity_ls)[idxs.sampled])[0]\n",
    "yhat = np.array(smiles_ls)[hits_idxs]\n",
    "yhat.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "b22c79ce-c32f-4281-ba67-6e0e5c9f1e04",
   "metadata": {},
   "outputs": [],
   "source": [
    "from rdkit.Chem.FilterCatalog import FilterCatalog, FilterCatalogParams\n",
    "\n",
    "pains_idxs = []\n",
    "\n",
    "# initialize filter\n",
    "params = FilterCatalogParams()\n",
    "params.AddCatalog(FilterCatalogParams.FilterCatalogs.PAINS)\n",
    "catalog = FilterCatalog(params)\n",
    "\n",
    "\n",
    "for i, mol in zip(range(len(mol_ls)), mol_ls):\n",
    "    entry = catalog.GetFirstMatch(mol)  # Get the first matching PAINS\n",
    "    if entry is not None:\n",
    "        pains_idxs.append(i)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "71d465a4-8478-464e-80ff-897f9fceca74",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "% PAINS: 0.03582985140272062\n",
      "% Hits: 0.03424334767993466\n",
      "# PAINs active: 116\n",
      "% PAINs active: 0.05321100917431193\n",
      "# PAINs sampled hit: 42\n",
      "% PAINs sampled hit: 0.03238242097147263\n"
     ]
    }
   ],
   "source": [
    "print(f\"% PAINS: {len(pains_idxs)/len(activity_ls)}\")\n",
    "print(f\"% Hits: {sum(activity_ls)/len(activity_ls)}\")\n",
    "\n",
    "print(f\"# PAINs active: {len(pains_idxs) + len(ytrue_idxs) - len(set(pains_idxs+list(ytrue_idxs)))}\")\n",
    "print(f\"% PAINs active: {(len(pains_idxs) + len(ytrue_idxs) - len(set(pains_idxs+list(ytrue_idxs)))) / len(ytrue_idxs)}\")\n",
    "\n",
    "print(f\"# PAINs sampled hit: {len(pains_idxs) + len(yhat_idxs) - len(set(pains_idxs+list(yhat_idxs)))}\")\n",
    "print(f\"% PAINs sampled hit: {(len(pains_idxs) + len(yhat_idxs) - len(set(pains_idxs+list(yhat_idxs)))) / len(yhat_idxs)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5dbfb27f-848c-48c9-9ce4-26a6c7b1bba7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# => not biasing towards PAINs"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Chem",
   "language": "python",
   "name": "chem"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
