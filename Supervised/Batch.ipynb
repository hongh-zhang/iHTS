{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "28fff0d6-0aee-41ff-afd4-1ee2b1b226a2",
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "\n",
    "import typing\n",
    "from typing import List, Iterable\n",
    "import pickle\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "import rdkit\n",
    "from rdkit.Chem import AllChem as AllChem\n",
    "from rdkit.SimDivFilters.rdSimDivPickers import MaxMinPicker\n",
    "\n",
    "from sklearn.ensemble import RandomForestClassifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "ccb9477e-3aea-4278-9d66-0c8a3bddc27a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1, 2]\n",
      "[0, 3, 4, 5, 6, 7, 8, 9]\n",
      "[8, 1, 2]\n",
      "[0, 3, 4, 5, 6, 7, 9]\n",
      "[8, 1, 2]\n",
      "[0, 3, 4, 5, 6, 7, 9]\n"
     ]
    }
   ],
   "source": [
    "def random_pick(fp_ls: List[rdkit.DataStructs.cDataStructs.ExplicitBitVect], \n",
    "                n: int, \n",
    "                seed: int = 42) -> List[int]:\n",
    "    \"\"\"Random diverse compound picking based on Rdkit MaxMinPicker\"\"\"\n",
    "    picker = MaxMinPicker()\n",
    "    return list(picker.LazyBitVectorPick(fp_ls, len(fp_ls), n, seed=seed))\n",
    "\n",
    "\n",
    "class Indice():\n",
    "    def __init__(self, size: int) -> None:\n",
    "        self.unsampled = list(range(size))\n",
    "        self.sampled = []\n",
    "        \n",
    "    def add(self, idxs: Iterable[int]) -> None:\n",
    "        self.sampled = list(set(self.sampled + list(idxs)))\n",
    "        self.unsampled = list(set(self.unsampled) - set(self.sampled))\n",
    "\n",
    "# test\n",
    "idxs = Indice(10)\n",
    "\n",
    "idxs.add([1,2])\n",
    "print(idxs.sampled)\n",
    "print(idxs.unsampled)\n",
    "\n",
    "idxs.add([1,2,8])\n",
    "print(idxs.sampled)\n",
    "print(idxs.unsampled)\n",
    "\n",
    "idxs.add([1,2,8])\n",
    "print(idxs.sampled)\n",
    "print(idxs.unsampled)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "affcf3b5-4849-43f8-8c43-4f64fbcf043d",
   "metadata": {},
   "outputs": [],
   "source": [
    "SEED = 0\n",
    "P_INIT = 0.15\n",
    "P_ITER = 0.05\n",
    "N_ITER = 4\n",
    "P_EXPLOIT = 0.8\n",
    "N_JOBS = 8\n",
    "    \n",
    "def iHTS(path: str):\n",
    "\n",
    "    with open(path,\"rb\") as file:\n",
    "        data = pickle.load(file)\n",
    "\n",
    "    smiles_ls = data.get(\"smiles_ls\")\n",
    "    mol_ls = data.get(\"mol_ls\")\n",
    "    fp_ls = data.get(\"fp_ls\")\n",
    "    activity_ls = data.get(\"activity_ls\")\n",
    "    ds_ls = data.get(\"ds_ls\")\n",
    "    N_TOTAL = len(fp_ls)\n",
    "    \n",
    "    del data\n",
    "\n",
    "    X = np.concatenate([np.array(ds_ls), np.array(fp_ls)], axis=1)\n",
    "    y = np.array(activity_ls)\n",
    "    \n",
    "\n",
    "    # define model\n",
    "    rf = RandomForestClassifier(n_estimators=1200, class_weight=\"balanced\",\n",
    "        max_features='log2',bootstrap=True,min_samples_split = 8,\n",
    "        min_samples_leaf = 3, n_jobs = N_JOBS,random_state=SEED)\n",
    "    \n",
    "    \n",
    "    clf = RandomForestClassifier(n_estimators=1200, class_weight=\"balanced\",\n",
    "    max_features='log2',bootstrap=True,min_samples_split = 8,\n",
    "    min_samples_leaf = 3, n_jobs = 4,random_state=SEED)\n",
    "\n",
    "    # select initial subset\n",
    "    init_idx = random_pick(fp_ls, int(P_INIT*len(fp_ls)))\n",
    "    idxs = Indice(len(fp_ls))\n",
    "    idxs.add(init_idx)\n",
    "\n",
    "    for it in range(N_ITER):\n",
    "        print(it)\n",
    "        \n",
    "        # train supversied model\n",
    "        # form dataset\n",
    "        X_sampled = X[idxs.sampled]\n",
    "        y_sampled = y[idxs.sampled]\n",
    "        X_unsampled = X[idxs.unsampled]\n",
    "\n",
    "        # fit & make prediction\n",
    "        clf.fit(X_sampled, y_sampled)\n",
    "        probs = clf.predict_proba(X_unsampled)[:,0]  # prob of being inactive\n",
    "\n",
    "        # select next batch\n",
    "        # add exploitation set\n",
    "        n_exploit = int(P_ITER * N_TOTAL * P_EXPLOIT)\n",
    "        idx_exploit = np.argsort(probs)[:n_exploit]  # sorted from low -> high\n",
    "        idxs.add(np.array(idxs.unsampled)[idx_exploit])\n",
    "\n",
    "        # add exploration set\n",
    "        n_explore = int(P_ITER * N_TOTAL * (1-P_EXPLOIT))\n",
    "        idx_explore = random_pick([fp_ls[i] for i in idxs.unsampled], n_explore)\n",
    "        idxs.add(np.array(idxs.unsampled)[idx_explore])\n",
    "\n",
    "    return idxs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "b9b44354-9b44-4676-8600-37b624d43c27",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(63662, 1121) (63662,)\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n"
     ]
    }
   ],
   "source": [
    "idxs1 = iHTS(\"dataset/AID_628/data.pkl\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "cd6e6c3b-2c10-4404-b067-138456ba14bb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(77674, 1121) (77674,)\n",
      "0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\25791\\.conda\\envs\\chem\\lib\\site-packages\\sklearn\\utils\\_array_api.py:380: RuntimeWarning: overflow encountered in cast\n",
      "  array = numpy.asarray(array, order=order, dtype=dtype)\n"
     ]
    }
   ],
   "source": [
    "try:\n",
    "    idxs2 = iHTS(\"dataset/test/AID_1259354/data.pkl\")\n",
    "except:\n",
    "    pass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "8a9cac3c-6b20-42c5-9d7d-245bf055dcdc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(2166, 1121) (2166,)\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n"
     ]
    }
   ],
   "source": [
    "try:\n",
    "    idxs3 = iHTS(\"dataset/test/AID_488969/data.pkl\")\n",
    "except:\n",
    "    pass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "673edb1e-d9ad-4ff7-b9f7-a7e6e0f20b97",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(85210, 1121) (85210,)\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n"
     ]
    }
   ],
   "source": [
    "try:\n",
    "    idxs4 = iHTS(\"dataset/test/AID_598/data.pkl\")\n",
    "except:\n",
    "    pass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "83e92fb9-f94e-4898-a11e-b4a45a3679b7",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "chem",
   "language": "python",
   "name": "chem"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
